{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b71d34cb",
   "metadata": {},
   "source": [
    "# Hyperparameters Optimization for the 2nd Model\n",
    "## *Autoregressive LSTM*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94322e7",
   "metadata": {},
   "source": [
    "This notebook is used for hyperparameter optimization of the model implemented in LSTMn°5.ipynb.\n",
    "\n",
    "We aim to optimize the LSTM model's hyperparameters by utilizing the full historical dataset (2015–2022) for training and validation. To accelerate the process, we will perform the optimization on a sample of stations, as the objective is to select the parameters that provide the best average performance across the station sample.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a83568b",
   "metadata": {},
   "source": [
    "## 1: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a712f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom utility functions used in the project\n",
    "import utils\n",
    "import AR_models\n",
    "\n",
    "import os\n",
    "\n",
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f021e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce2e99a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a9b7f1",
   "metadata": {},
   "source": [
    "## 2: Hyperparameters Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c65014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "x_train = x_train = pd.read_csv('train_f_x.csv')\n",
    "y_train = pd.read_csv('y_train_sncf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8421576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "df_per_station = utils.prepare_backtest_data(x_train, y_train, remove_covid=True)\n",
    "\n",
    "# Exclude Recent stations\n",
    "RECENT = ['QD6', 'P6E', 'BDC', 'W80', 'W14']\n",
    "df_per_station = utils.filter_stations(df_per_station, RECENT)\n",
    "\n",
    "# Split into train and test dataset\n",
    "df_train = {}\n",
    "df_test = {}\n",
    "for station in df_per_station:\n",
    "    df_train_station, df_test_station = utils.split_dataset(df_per_station[station])\n",
    "    df_train[station] = df_train_station\n",
    "    df_test[station] = df_test_station\n",
    "\n",
    "# Verification\n",
    "print(\"len(df_train):\",len(df_train),\":\",df_train.keys())\n",
    "print(\"len(df_test):\",len(df_test),\":\",df_train.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21638b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample of stations\n",
    "sample_size = 50\n",
    "seed = 856\n",
    "\n",
    "# train\n",
    "sample_train = utils.sample_stations(df_train, sample_size, seed)\n",
    "print(\"sample_train: \", sample_train.keys())\n",
    "\n",
    "# test\n",
    "sample_test = {\n",
    "    station: df_test[station].copy()\n",
    "    for station in sample_train.keys()\n",
    "}\n",
    "\n",
    "print(\"sample_test: \", sample_test.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7220e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep true values \n",
    "sample_test_true = {\n",
    "    station: df_test[station].copy()\n",
    "    for station in sample_test.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c626b166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Optuna objective function to minimize the average MAPE score \n",
    "    across the station sample.\n",
    "    \"\"\"\n",
    "    # 1. Define the search space\n",
    "    params = {\n",
    "        \"units\": trial.suggest_int(\"units\", 40, 80, step=10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 20, 50, step=10),\n",
    "        \"seq_len\": trial.suggest_int(\"seq_len\", 50, 120, step=10)\n",
    "    }\n",
    "\n",
    "    # 2. Create copies of the test data to prevent trials from overwriting \n",
    "    # the original sample_test dictionary\n",
    "    trial_sample_test = copy.deepcopy(sample_test)\n",
    "\n",
    "    try:\n",
    "        # 3. Call backtest_lstm with suggested parameters\n",
    "        # REMOVED 'sample_size' from the call to fix the multiple values error\n",
    "        _, mape_results, _ = AR_models.lstm_backtest_autoregressive(\n",
    "            sample_train, \n",
    "            trial_sample_test, \n",
    "            sample_test_true, \n",
    "            seq_len=params[\"seq_len\"],\n",
    "            units=params[\"units\"],\n",
    "            activation='tanh',\n",
    "            learning_rate=params[\"learning_rate\"],\n",
    "            batch_size=params[\"batch_size\"]\n",
    "        )\n",
    "\n",
    "        # 4. Handle failed trials within the backtest\n",
    "        if not mape_results:\n",
    "            return float('inf')\n",
    "\n",
    "        # 5. Calculate the MEAN MAPE across all stations in the sample\n",
    "        # This makes the hyperparameters generalize better across different stations\n",
    "        all_mapes = [res['MAPE'] for res in mape_results]\n",
    "        average_mape = np.mean(all_mapes)\n",
    "        \n",
    "        return average_mape\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Trial failed with error: {e}\")\n",
    "        return float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0b4fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution\n",
    "run = 1\n",
    "if (run == 1):\n",
    "    study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler())\n",
    "    study.optimize(lambda trial: objective(trial), n_trials=30)\n",
    "else:\n",
    "    print(\"run == 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193d2c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters:\", study.best_params)\n",
    "print(\"Best average MAPE:\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02590dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters: {'units': 60, 'learning_rate': 0.00654598082698137, 'batch_size': 20, 'seq_len': 70}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

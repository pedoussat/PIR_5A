{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65ddeb67",
   "metadata": {},
   "source": [
    "# Hyperparameters Optimization for the 3rd Model\n",
    "## *Feature-Enriched Non-Autoregressive LSTM*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33350f4",
   "metadata": {},
   "source": [
    "## 1: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea45e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom functions\n",
    "import utils\n",
    "import NAR_models\n",
    "\n",
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb49d282",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b16d4e",
   "metadata": {},
   "source": [
    "## 2: Hyperparameters Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1299c9",
   "metadata": {},
   "source": [
    "### 2.1: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b62f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "x_train_new  = pd.read_csv('x_train_new.csv')\n",
    "y_train_new = pd.read_csv('y_train_sncf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f7842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "df_per_station = utils.prepare_backtest_data(x_train_new, y_train_new, remove_covid=True)\n",
    "\n",
    "# Exclude Recent stations\n",
    "RECENT = ['QD6', 'P6E', 'BDC', 'W80', 'W14']\n",
    "df_per_station = utils.filter_stations(df_per_station, RECENT)\n",
    "\n",
    "# Split into train and test dataset\n",
    "df_train = {}\n",
    "df_test = {}\n",
    "for station in df_per_station:\n",
    "    df_train_station, df_test_station = utils.split_dataset(df_per_station[station])\n",
    "    df_train[station] = df_train_station\n",
    "    df_test[station] = df_test_station\n",
    "\n",
    "# Verification\n",
    "print(\"len(df_train):\",len(df_train),\":\",df_train.keys())\n",
    "print(\"len(df_test):\",len(df_test),\":\",df_train.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8fd156",
   "metadata": {},
   "source": [
    "### 2.2: Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a776112",
   "metadata": {},
   "source": [
    "Hyperparameter tuning is conducted on a subset of 40 stations to significantly reduce runtime, under the assumption that optimal hyperparameters generalize across stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a248322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample of stations\n",
    "sample_size = 50\n",
    "seed = 365\n",
    "\n",
    "# train\n",
    "sample_train = utils.sample_stations(df_train, sample_size, seed)\n",
    "print(\"sample_train: \", sample_train.keys())\n",
    "\n",
    "# test\n",
    "sample_test = {\n",
    "    station: df_test[station].copy()\n",
    "    for station in sample_train.keys()\n",
    "}\n",
    "\n",
    "print(\"sample_test: \", sample_test.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a941a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep true values for MAPE computation\n",
    "sample_test_true = {\n",
    "    station: df_test[station].copy()\n",
    "    for station in sample_test.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1efe75b",
   "metadata": {},
   "source": [
    "### 2.3: Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f62824",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['job','ferie','vacances','dow_sin','dow_cos','month_sin','month_cos']\n",
    "activation = 'tanh'\n",
    "epochs = 50\n",
    "early_stop=True\n",
    "keep_percentage = 0.25\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Optuna objective function to minimize the average MAPE score \n",
    "    across the station sample.\n",
    "    \"\"\"\n",
    "    # 1. Define the search space\n",
    "    params = {\n",
    "        \"units\": trial.suggest_int(\"units\", 40, 80, step=4),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 16, 56, step=10),\n",
    "        \"seq_len\": trial.suggest_int(\"seq_len\", 30, 120, step=10)\n",
    "    }\n",
    "\n",
    "    # 2. Create copies of the test data to prevent trials from overwriting \n",
    "    # the original sample_test dictionary\n",
    "    trial_sample_test = copy.deepcopy(sample_test)\n",
    "\n",
    "    try:\n",
    "        # 3. Call backtest_lstm with suggested parameters\n",
    "        # ignore the returned df and losses to save memory during optimization\n",
    "        _, mape_results, _ = NAR_models.backtest_lstm( \n",
    "            sample_train, \n",
    "            trial_sample_test, \n",
    "            sample_test_true, \n",
    "            sample_size,\n",
    "            seq_len=params[\"seq_len\"],\n",
    "            units=params[\"units\"],\n",
    "            activation='tanh',\n",
    "            learning_rate=params[\"learning_rate\"],\n",
    "            batch_size=params[\"batch_size\"],\n",
    "            epochs=epochs, \n",
    "            keep_percentage = keep_percentage,\n",
    "            early_stop=early_stop, \n",
    "            features=features\n",
    "        )\n",
    "\n",
    "        # 4. Handle failed trials within the backtest\n",
    "        if not mape_results:\n",
    "            return float('inf')\n",
    "\n",
    "        # 5. Calculate the MEAN MAPE across all stations in the sample\n",
    "        # This makes the hyperparameters generalize better across different stations\n",
    "        all_mapes = [res['MAPE'] for res in mape_results]\n",
    "        average_mape = np.mean(all_mapes)\n",
    "        \n",
    "        return average_mape\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Trial failed with error: {e}\")\n",
    "        return float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225d4909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution Flag\n",
    "run = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8d6da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution\n",
    "if (run == 1):\n",
    "    study = optuna.create_study(direction=\"minimize\", sampler=TPESampler())\n",
    "    study.optimize(lambda trial: objective(trial), n_trials=30)\n",
    "else:\n",
    "    print(\"run == 0, no execution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276e09da",
   "metadata": {},
   "source": [
    "### 2.4: Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e31a06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best params found: {'units': 64, 'learning_rate': 0.006172885794840763, 'batch_size': 16, 'seq_len': 100}\n",
    "# Best average MAPE: 0.956"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8944e5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters:\", study.best_params)\n",
    "print(\"Best average MAPE:\", study.best_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0c5e3db",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization for Recent Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7854d9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(\n",
    "    os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ad6bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import importlib\n",
    "import utils\n",
    "import modelsRecent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e3c20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case of 'modelsRecent.py' modifications\n",
    "importlib.reload(modelsRecent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69888f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_stations(data_dict, stations_to_include):\n",
    "    return {\n",
    "        station: df for station, df in data_dict.items() \n",
    "        if station in stations_to_include\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0163e896",
   "metadata": {},
   "outputs": [],
   "source": [
    "RECENT_STATIONS = ['P6E', 'BDC', 'W80'] # W14 and QD6 are treated in another notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91814280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "x_train = x_train = pd.read_csv('train_f_x.csv')\n",
    "y_train = pd.read_csv('y_train_sncf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab58f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "df = utils.prepare_backtest_data(x_train, y_train, remove_covid=True)\n",
    "\n",
    "# Extract recent stations data\n",
    "df_recent = filter_stations(df, RECENT_STATIONS)\n",
    "\n",
    "# Split into train and test dataset\n",
    "df_train = {}\n",
    "df_test = {}\n",
    "for station in df_recent:\n",
    "    df_train_station, df_test_station = utils.split_dataset(df_recent[station], cut_date='2022-09-17')\n",
    "    df_train[station] = df_train_station\n",
    "    df_test[station] = df_test_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2e5db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep true values \n",
    "df_test_true = {\n",
    "    station: df_test[station].copy()\n",
    "    for station in df_test.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96f2ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import optuna\n",
    "import tqdm\n",
    "from optuna.samplers import TPESampler\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd789d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveRNN(trial):\n",
    "    \"\"\"\n",
    "    Optuna objective function to minimize the average MAPE score \n",
    "    across the stations.\n",
    "    \"\"\"\n",
    "    # Define the search space for hyperparameters\n",
    "    params = {\n",
    "        \"units\": trial.suggest_int(\"units\", 30, 60, step=5),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True),\n",
    "        \"batch_size\": trial.suggest_categorical(\"batch_size\", [15, 20, 25, 30, 35, 40]),\n",
    "        \"seq_len\": trial.suggest_int(\"seq_len\", 10, 40, step=5)\n",
    "    }\n",
    "\n",
    "    trial_sample_test = copy.deepcopy(df_test)\n",
    "\n",
    "    try:\n",
    "        # 3. Call backtest_lstm with suggested parameters\n",
    "        # We ignore the returned df and losses to save memory during optimization\n",
    "        _, mape_results, _ = modelsRecent.backtest_model(\n",
    "            df_train, \n",
    "            trial_sample_test, \n",
    "            df_test_true, \n",
    "            seq_len=params[\"seq_len\"],\n",
    "            units=params[\"units\"],\n",
    "            activation='tanh',\n",
    "            learning_rate=params[\"learning_rate\"],\n",
    "            batch_size=params[\"batch_size\"],\n",
    "            epochs=100, \n",
    "            keep_percentage=0.5,\n",
    "            early_stop=True, \n",
    "            features=['job', 'ferie', 'vacances'],\n",
    "            architecture = 'rnn'\n",
    "        )\n",
    "\n",
    "        # 4. Handle failed trials within the backtest\n",
    "        if not mape_results:\n",
    "            return float('inf')\n",
    "\n",
    "        # 5. Calculate the MEAN MAPE across all stations in the sample\n",
    "        # This makes the hyperparameters generalize better across different stations\n",
    "        all_mapes = [res['MAPE'] for res in mape_results]\n",
    "        average_mape = np.mean(all_mapes)\n",
    "        \n",
    "        return average_mape\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Trial failed with error: {e}\")\n",
    "        return float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efc75f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveLSTM(trial):\n",
    "    \"\"\"\n",
    "    Optuna objective function to minimize the average MAPE score \n",
    "    across the stations.\n",
    "    \"\"\"\n",
    "    # Define the search space for hyperparameters\n",
    "    params = {\n",
    "        \"units\": trial.suggest_int(\"units\", 30, 60, step=5),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True),\n",
    "        \"batch_size\": trial.suggest_categorical(\"batch_size\", [15, 20, 25, 30, 35, 40]),\n",
    "        \"seq_len\": trial.suggest_int(\"seq_len\", 10, 40, step=5)\n",
    "    }\n",
    "\n",
    "    trial_sample_test = copy.deepcopy(df_test)\n",
    "\n",
    "    try:\n",
    "        # 3. Call backtest_lstm with suggested parameters\n",
    "        # We ignore the returned df and losses to save memory during optimization\n",
    "        _, mape_results, _ = modelsRecent.backtest_model(\n",
    "            df_train, \n",
    "            trial_sample_test, \n",
    "            df_test_true, \n",
    "            seq_len=params[\"seq_len\"],\n",
    "            units=params[\"units\"],\n",
    "            activation='tanh',\n",
    "            learning_rate=params[\"learning_rate\"],\n",
    "            batch_size=params[\"batch_size\"],\n",
    "            epochs=100, \n",
    "            keep_percentage=0.5,\n",
    "            early_stop=True, \n",
    "            features=['job', 'ferie', 'vacances'],\n",
    "            architecture = 'lstm'\n",
    "        )\n",
    "\n",
    "        # 4. Handle failed trials within the backtest\n",
    "        if not mape_results:\n",
    "            return float('inf')\n",
    "\n",
    "        # 5. Calculate the MEAN MAPE across all stations in the sample\n",
    "        # This makes the hyperparameters generalize better across different stations\n",
    "        all_mapes = [res['MAPE'] for res in mape_results]\n",
    "        average_mape = np.mean(all_mapes)\n",
    "        \n",
    "        return average_mape\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Trial failed with error: {e}\")\n",
    "        return float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1a4139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run flag\n",
    "run_flag = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9680c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (run_flag == 1):\n",
    "    # Create and run the study\n",
    "    studyRNN = optuna.create_study(direction=\"minimize\")\n",
    "    studyRNN.optimize(objectiveRNN, n_trials=35)\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Increment the run flag\n",
    "    run_flag+=1\n",
    "\n",
    "    # Display results\n",
    "    print(f\"Best MAPE: {studyRNN.best_value:.4f}\")\n",
    "    print(\"Best Hyperparameters for RNN:\", studyRNN.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6f680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (run_flag == 2):\n",
    "    # Create and run the study\n",
    "    studyLSTM = optuna.create_study(direction=\"minimize\")\n",
    "    studyLSTM.optimize(objectiveLSTM, n_trials=35)\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Increment the run flag\n",
    "    run_flag+=1\n",
    "\n",
    "    # Display results\n",
    "    print(f\"Best MAPE: {studyLSTM.best_value:.4f}\")\n",
    "    print(\"Best Hyperparameters for LSTM:\", studyLSTM.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21625347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Hyperparameters for RNN: {'units': 50, 'learning_rate': 0.004511134598760262, 'batch_size': 15, 'seq_len': 25}\n",
    "# Best MAPE: 0.3443\n",
    "#\n",
    "# Best Hyperparameters for LSTM: {'units': 50, 'learning_rate': 0.00010728642971712255, 'batch_size': 15, 'seq_len': 25}\n",
    "# Best MAPE: 0.4241"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
